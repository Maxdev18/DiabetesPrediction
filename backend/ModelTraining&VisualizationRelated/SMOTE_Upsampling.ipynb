{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 29\u001B[0m\n\u001B[0;32m     25\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m     27\u001B[0m smote \u001B[38;5;241m=\u001B[39m SMOTE(sampling_strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m---> 29\u001B[0m X_train_resampled, y_train_resampled \u001B[38;5;241m=\u001B[39m \u001B[43msmote\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\OneDrive\\Desktop\\Assignments\\CMPSC 445\\project\\pgrm\\venv\\lib\\site-packages\\imblearn\\base.py:208\u001B[0m, in \u001B[0;36mBaseSampler.fit_resample\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Resample the dataset.\u001B[39;00m\n\u001B[0;32m    188\u001B[0m \n\u001B[0;32m    189\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;124;03m    The corresponding label of `X_resampled`.\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m--> 208\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\OneDrive\\Desktop\\Assignments\\CMPSC 445\\project\\pgrm\\venv\\lib\\site-packages\\imblearn\\base.py:112\u001B[0m, in \u001B[0;36mSamplerMixin.fit_resample\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    106\u001B[0m X, y, binarize_y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_X_y(X, y)\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_strategy_ \u001B[38;5;241m=\u001B[39m check_sampling_strategy(\n\u001B[0;32m    109\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_strategy, y, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampling_type\n\u001B[0;32m    110\u001B[0m )\n\u001B[1;32m--> 112\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m y_ \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    115\u001B[0m     label_binarize(output[\u001B[38;5;241m1\u001B[39m], classes\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39munique(y)) \u001B[38;5;28;01mif\u001B[39;00m binarize_y \u001B[38;5;28;01melse\u001B[39;00m output[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    116\u001B[0m )\n\u001B[0;32m    118\u001B[0m X_, y_ \u001B[38;5;241m=\u001B[39m arrays_transformer\u001B[38;5;241m.\u001B[39mtransform(output[\u001B[38;5;241m0\u001B[39m], y_)\n",
      "File \u001B[1;32mE:\\OneDrive\\Desktop\\Assignments\\CMPSC 445\\project\\pgrm\\venv\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:364\u001B[0m, in \u001B[0;36mSMOTE._fit_resample\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    361\u001B[0m X_class \u001B[38;5;241m=\u001B[39m _safe_indexing(X, target_class_indices)\n\u001B[0;32m    363\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnn_k_\u001B[38;5;241m.\u001B[39mfit(X_class)\n\u001B[1;32m--> 364\u001B[0m nns \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn_k_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkneighbors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[:, \u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m    365\u001B[0m X_new, y_new \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_samples(\n\u001B[0;32m    366\u001B[0m     X_class, y\u001B[38;5;241m.\u001B[39mdtype, class_sample, X_class, nns, n_samples, \u001B[38;5;241m1.0\u001B[39m\n\u001B[0;32m    367\u001B[0m )\n\u001B[0;32m    368\u001B[0m X_resampled\u001B[38;5;241m.\u001B[39mappend(X_new)\n",
      "File \u001B[1;32mE:\\OneDrive\\Desktop\\Assignments\\CMPSC 445\\project\\pgrm\\venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py:877\u001B[0m, in \u001B[0;36mKNeighborsMixin.kneighbors\u001B[1;34m(self, X, n_neighbors, return_distance)\u001B[0m\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m issparse(X):\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    873\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m does not work with sparse matrices. Densify the data, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    874\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor set algorithm=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbrute\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    875\u001B[0m             \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_method\n\u001B[0;32m    876\u001B[0m         )\n\u001B[1;32m--> 877\u001B[0m     chunked_results \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mthreads\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_tree_query_parallel_helper\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tree\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43ms\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_neighbors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_distance\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    881\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgen_even_slices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    882\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    883\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    884\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minternal: _fit_method not recognized\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mE:\\OneDrive\\Desktop\\Assignments\\CMPSC 445\\project\\pgrm\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     64\u001B[0m )\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\OneDrive\\Desktop\\Assignments\\CMPSC 445\\project\\pgrm\\venv\\lib\\site-packages\\joblib\\parallel.py:1863\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1861\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1862\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1863\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1865\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1866\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1867\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1868\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1869\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1870\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32mE:\\OneDrive\\Desktop\\Assignments\\CMPSC 445\\project\\pgrm\\venv\\lib\\site-packages\\joblib\\parallel.py:1792\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1790\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1791\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1792\u001B[0m res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1793\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1794\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32mE:\\OneDrive\\Desktop\\Assignments\\CMPSC 445\\project\\pgrm\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    125\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\OneDrive\\Desktop\\Assignments\\CMPSC 445\\project\\pgrm\\venv\\lib\\site-packages\\sklearn\\neighbors\\_base.py:683\u001B[0m, in \u001B[0;36m_tree_query_parallel_helper\u001B[1;34m(tree, *args, **kwargs)\u001B[0m\n\u001B[0;32m    677\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_tree_query_parallel_helper\u001B[39m(tree, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    678\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Helper for the Parallel calls in KNeighborsMixin.kneighbors.\u001B[39;00m\n\u001B[0;32m    679\u001B[0m \n\u001B[0;32m    680\u001B[0m \u001B[38;5;124;03m    The Cython method tree.query is not directly picklable by cloudpickle\u001B[39;00m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;124;03m    under PyPy.\u001B[39;00m\n\u001B[0;32m    682\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 683\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tree\u001B[38;5;241m.\u001B[39mquery(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'filtered_normalized_data_replace2to1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "X = df.drop('Diabetes_012', axis=1).values\n",
    "y = df['Diabetes_012'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:41:11.321900700Z",
     "start_time": "2023-10-30T19:41:03.471900300Z"
    }
   },
   "id": "49c61f6b558a397c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random Forest with SMOTE\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "avg_precision = {0: 0, 1: 0}\n",
    "avg_recall = {0: 0, 1: 0}\n",
    "avg_f1_score = {0: 0, 1: 0}\n",
    "\n",
    "# k-fold k=5\n",
    "kf = KFold(n_splits=5, random_state=445, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_resampled):\n",
    "    X_train_kf, X_test_kf = X_train_resampled[train_index], X_train_resampled[test_index]\n",
    "    y_train_kf, y_test_kf = y_train_resampled[train_index], y_train_resampled[test_index]\n",
    "    \n",
    "    clf.fit(X_train_kf, y_train_kf)\n",
    "    y_pred_kf = clf.predict(X_test_kf)\n",
    "    \n",
    "    print(classification_report(y_test_kf, y_pred_kf))\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test_kf, y_pred_kf, average=None)\n",
    "    \n",
    "    for i in [0, 1]:\n",
    "        avg_precision[i] += precision[i]\n",
    "        avg_recall[i] += recall[i]\n",
    "        avg_f1_score[i] += f1_score[i]\n",
    "\n",
    "avg_precision = {k: v / 5 for k, v in avg_precision.items()}\n",
    "avg_recall = {k: v / 5 for k, v in avg_recall.items()}\n",
    "avg_f1_score = {k: v / 5 for k, v in avg_f1_score.items()}\n",
    "\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"Average F1-Score:\", avg_f1_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T19:41:11.315400700Z"
    }
   },
   "id": "fae6f216e6289ac9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Logistic Regression with SMOTE\n",
    "clf = LogisticRegression(max_iter=3000, solver='lbfgs')\n",
    "\n",
    "# Initialize average metrics dictionary\n",
    "avg_precision = {0: 0, 1: 0}\n",
    "avg_recall = {0: 0, 1: 0}\n",
    "avg_f1_score = {0: 0, 1: 0}\n",
    "\n",
    "# k-fold k=5\n",
    "kf = KFold(n_splits=5, random_state=445, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_resampled):\n",
    "    X_train_kf, X_test_kf = X_train_resampled[train_index], X_train_resampled[test_index]\n",
    "    y_train_kf, y_test_kf = y_train_resampled[train_index], y_train_resampled[test_index]\n",
    "    \n",
    "    clf.fit(X_train_kf, y_train_kf)\n",
    "    y_pred_kf = clf.predict(X_test_kf)\n",
    "    \n",
    "    print(classification_report(y_test_kf, y_pred_kf))\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test_kf, y_pred_kf, average=None)\n",
    "    \n",
    "    for i in [0, 1]:\n",
    "        avg_precision[i] += precision[i]\n",
    "        avg_recall[i] += recall[i]\n",
    "        avg_f1_score[i] += f1_score[i]\n",
    "\n",
    "avg_precision = {k: v / 5 for k, v in avg_precision.items()}\n",
    "avg_recall = {k: v / 5 for k, v in avg_recall.items()}\n",
    "avg_f1_score = {k: v / 5 for k, v in avg_f1_score.items()}\n",
    "\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"Average F1-Score:\", avg_f1_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T19:41:11.316900200Z"
    }
   },
   "id": "800364ada99472d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors (KNN) with SMOTE\n",
    "clf = KNeighborsClassifier(n_neighbors=5, algorithm='auto')\n",
    "\n",
    "avg_precision = {0: 0, 1: 0}\n",
    "avg_recall = {0: 0, 1: 0}\n",
    "avg_f1_score = {0: 0, 1: 0}\n",
    "\n",
    "# k-fold k=5\n",
    "kf = KFold(n_splits=5, random_state=445, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_resampled):\n",
    "    X_train_kf, X_test_kf = X_train_resampled[train_index], X_train_resampled[test_index]\n",
    "    y_train_kf, y_test_kf = y_train_resampled[train_index], y_train_resampled[test_index]\n",
    "    \n",
    "    clf.fit(X_train_kf, y_train_kf)\n",
    "    y_pred_kf = clf.predict(X_test_kf)\n",
    "    \n",
    "    print(classification_report(y_test_kf, y_pred_kf))\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test_kf, y_pred_kf, average=None)\n",
    "    \n",
    "    for i in [0, 1]:\n",
    "        avg_precision[i] += precision[i]\n",
    "        avg_recall[i] += recall[i]\n",
    "        avg_f1_score[i] += f1_score[i]\n",
    "\n",
    "avg_precision = {k: v / 5 for k, v in avg_precision.items()}\n",
    "avg_recall = {k: v / 5 for k, v in avg_recall.items()}\n",
    "avg_f1_score = {k: v / 5 for k, v in avg_f1_score.items()}\n",
    "\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"Average F1-Score:\", avg_f1_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T19:41:11.318899900Z"
    }
   },
   "id": "9cc6f70f0bb8bc3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Decision Tree with SMOTE\n",
    "clf = DecisionTreeClassifier(criterion='gini', splitter='best', random_state=42)\n",
    "\n",
    "avg_precision = {0: 0, 1: 0}\n",
    "avg_recall = {0: 0, 1: 0}\n",
    "avg_f1_score = {0: 0, 1: 0}\n",
    "\n",
    "# k-fold k=5\n",
    "kf = KFold(n_splits=5, random_state=445, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_resampled):\n",
    "    X_train_kf, X_test_kf = X_train_resampled[train_index], X_train_resampled[test_index]\n",
    "    y_train_kf, y_test_kf = y_train_resampled[train_index], y_train_resampled[test_index]\n",
    "    \n",
    "    clf.fit(X_train_kf, y_train_kf)\n",
    "    y_pred_kf = clf.predict(X_test_kf)\n",
    "    \n",
    "    print(classification_report(y_test_kf, y_pred_kf))\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test_kf, y_pred_kf, average=None)\n",
    "    \n",
    "    for i in [0, 1]:\n",
    "        avg_precision[i] += precision[i]\n",
    "        avg_recall[i] += recall[i]\n",
    "        avg_f1_score[i] += f1_score[i]\n",
    "\n",
    "avg_precision = {k: v / 5 for k, v in avg_precision.items()}\n",
    "avg_recall = {k: v / 5 for k, v in avg_recall.items()}\n",
    "avg_f1_score = {k: v / 5 for k, v in avg_f1_score.items()}\n",
    "\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"Average F1-Score:\", avg_f1_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T19:41:11.320899700Z"
    }
   },
   "id": "b6820a1b2d4c2c28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Gradient Boosting with SMOTE\n",
    "clf = GradientBoostingClassifier(learning_rate=0.1, n_estimators=100)\n",
    "\n",
    "avg_precision = {0: 0, 1: 0}\n",
    "avg_recall = {0: 0, 1: 0}\n",
    "avg_f1_score = {0: 0, 1: 0}\n",
    "\n",
    "# k-fold k=5\n",
    "kf = KFold(n_splits=5, random_state=445, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_resampled):\n",
    "    X_train_kf, X_test_kf = X_train_resampled[train_index], X_train_resampled[test_index]\n",
    "    y_train_kf, y_test_kf = y_train_resampled[train_index], y_train_resampled[test_index]\n",
    "    \n",
    "    clf.fit(X_train_kf, y_train_kf)\n",
    "    y_pred_kf = clf.predict(X_test_kf)\n",
    "    \n",
    "    print(classification_report(y_test_kf, y_pred_kf))\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test_kf, y_pred_kf, average=None)\n",
    "    \n",
    "    for i in [0, 1]:\n",
    "        avg_precision[i] += precision[i]\n",
    "        avg_recall[i] += recall[i]\n",
    "        avg_f1_score[i] += f1_score[i]\n",
    "\n",
    "avg_precision = {k: v / 5 for k, v in avg_precision.items()}\n",
    "avg_recall = {k: v / 5 for k, v in avg_recall.items()}\n",
    "avg_f1_score = {k: v / 5 for k, v in avg_f1_score.items()}\n",
    "\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"Average F1-Score:\", avg_f1_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:41:11.322899500Z",
     "start_time": "2023-10-30T19:41:11.322400100Z"
    }
   },
   "id": "5a62070e374834d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# XGBoost with SMOTE\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "avg_precision = {0: 0, 1: 0}\n",
    "avg_recall = {0: 0, 1: 0}\n",
    "avg_f1_score = {0: 0, 1: 0}\n",
    "\n",
    "# k-fold k=5\n",
    "kf = KFold(n_splits=5, random_state=445, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train_resampled):\n",
    "    X_train_kf, X_test_kf = X_train_resampled[train_index], X_train_resampled[test_index]\n",
    "    y_train_kf, y_test_kf = y_train_resampled[train_index], y_train_resampled[test_index]\n",
    "    \n",
    "    clf.fit(X_train_kf, y_train_kf)\n",
    "    y_pred_kf = clf.predict(X_test_kf)\n",
    "    \n",
    "    print(classification_report(y_test_kf, y_pred_kf))\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_test_kf, y_pred_kf, average=None)\n",
    "    \n",
    "    for i in [0, 1]:\n",
    "        avg_precision[i] += precision[i]\n",
    "        avg_recall[i] += recall[i]\n",
    "        avg_f1_score[i] += f1_score[i]\n",
    "\n",
    "avg_precision = {k: v / 5 for k, v in avg_precision.items()}\n",
    "avg_recall = {k: v / 5 for k, v in avg_recall.items()}\n",
    "avg_f1_score = {k: v / 5 for k, v in avg_f1_score.items()}\n",
    "\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"Average F1-Score:\", avg_f1_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T19:41:11.323900800Z"
    }
   },
   "id": "9e0896996677c445"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
